{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Big Data Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Background\n",
    "\n",
    "When it comes to football bets, for every single game, we have different bets houses (with different mathematical models) that are generating three different quotas for the three different results of that game (win home, draw, win away).\n",
    "\n",
    "<img src=\"../Img/introduction.png\">\n",
    "\n",
    "As it can be seen in the picture above, for the same game (Inglaterra vs Panamá), the three bets houses are offering different quotas for the three possible results of the match.\n",
    "\n",
    "Most of the times, this quotas are pretty much the same (for example, the three of them are offering 1.22 for Inglaterra winning, and more or less 6 euros for a draw). But, there are a few times when the mathematical models have big discrepancies. For example, for Panamá winning, in this cases, bet365 is offering 4 euros more than the other two bets houses. \n",
    "\n",
    "So, in this case, for the model of bet365 a win for Panamá is much less probable than for the other two bets houses.\n",
    "\n",
    "The main idea behind this project is to study this big discrepancies between bets houses and try to use them (if it’s possible) to predict the final result of the match.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Objective\n",
    "\n",
    "The general objective of this project is increase the benefits in the management of bets of our customer. This will be achieved through the following specific objectives:\n",
    "\n",
    "- Create a prediction model of results based on discrepancies between mathematical models of different betting houses for the same match, within the framework of a country and competition.\n",
    "\n",
    "\n",
    "- Design of a method to identify matches with greater divergence between forecasts and therefore with more possibility of benefit if the result is correct.\n",
    "\n",
    "\n",
    "- Determine the reliability of betting houses, evaluating the success rate by comparing their odds with the result of the matches.\n",
    "\n",
    "\n",
    "- Identify if there is specialization of betting houses in a country, competition or team. Evaluate their highest success rate with respect to the different variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Approach\n",
    "\n",
    "So, first of all, we need to get the data. Searching on internet we have found this page:\n",
    "http://www.football-data.co.uk/data.php. \n",
    "\n",
    "The data in this page it is being updated every single week with the results of the games from that week.\n",
    "\n",
    "The data structure is the following:\n",
    "\n",
    "<img src=\"../Img/leagues_seasons.gif\">\n",
    "\n",
    "We have a set of leagues divided between main leagues and extra leagues. The difference between main leagues and extra leagues is, basically, that main leagues have more bets houses than extra leagues. Within a league, we have all the different seasons (starting in all of leagues by 2003-2004 more or less). And, finally, within a season, we have all the results from that season distributed in different csv files (one for each competition).\n",
    "\n",
    "To get all this data, we have generated a python script that basically builds all the different urls of all the files and download all of them. Also, this script builds our own filesystem that has the following structure: Country > Competition > Season.\n",
    "\n",
    "<img src=\"../Img/download.gif\">\n",
    "\n",
    "We download all the information but, by now, we have decided to use only the one coming from the main leagues as we have more information about bets houses.\n",
    "\n",
    "The data from this page is very consistent, but, we have found some little problems. One of them is that not all the files in the main leagues has the same format. Some of them have more bet houses than others (depending on the country generally). Another of the problems is that not all the countries data are starting on the same season. \n",
    "So, basically, what we have done is to take a look in all the competitions and select a starting season from which we have information from all the competitions. Finally, to have the same amount of bet houses, we have created empty columns for the missing ones in all the competitions files.\n",
    "\n",
    "Finally, we have join all this information coming from main leagues into a single file (keeping only le columns with valuable information) and exploit this data a little bit to get some interesting information as which is the bet house with more hit ratio, which are the bet houses that usually offer bets above or below the average...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Competition</th>\n",
       "      <th>Season</th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTR</th>\n",
       "      <th>WHH</th>\n",
       "      <th>WHD</th>\n",
       "      <th>WHA</th>\n",
       "      <th>SBH</th>\n",
       "      <th>SBD</th>\n",
       "      <th>SBA</th>\n",
       "      <th>IWH</th>\n",
       "      <th>IWD</th>\n",
       "      <th>IWA</th>\n",
       "      <th>GBH</th>\n",
       "      <th>GBD</th>\n",
       "      <th>GBA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13327</th>\n",
       "      <td>England</td>\n",
       "      <td>Conference</td>\n",
       "      <td>2008-2009</td>\n",
       "      <td>EC</td>\n",
       "      <td>2008-09-20</td>\n",
       "      <td>Rushden &amp; D</td>\n",
       "      <td>Burton</td>\n",
       "      <td>H</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5718</th>\n",
       "      <td>England</td>\n",
       "      <td>Championship</td>\n",
       "      <td>2007-2008</td>\n",
       "      <td>E1</td>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Cardiff</td>\n",
       "      <td>Sheffield Weds</td>\n",
       "      <td>H</td>\n",
       "      <td>1.73</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.85</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19366</th>\n",
       "      <td>England</td>\n",
       "      <td>League1</td>\n",
       "      <td>2006-2007</td>\n",
       "      <td>E2</td>\n",
       "      <td>2007-06-04</td>\n",
       "      <td>Scunthorpe</td>\n",
       "      <td>Yeovil</td>\n",
       "      <td>H</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.30</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.73</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21120</th>\n",
       "      <td>England</td>\n",
       "      <td>League1</td>\n",
       "      <td>2010-2011</td>\n",
       "      <td>E2</td>\n",
       "      <td>2010-08-21</td>\n",
       "      <td>Peterboro</td>\n",
       "      <td>Huddersfield</td>\n",
       "      <td>H</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.35</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38896</th>\n",
       "      <td>France</td>\n",
       "      <td>Division2</td>\n",
       "      <td>2006-2007</td>\n",
       "      <td>F2</td>\n",
       "      <td>2006-08-09</td>\n",
       "      <td>Bastia</td>\n",
       "      <td>Dijon</td>\n",
       "      <td>D</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.75</td>\n",
       "      <td>4.25</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.88</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.85</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34777</th>\n",
       "      <td>England</td>\n",
       "      <td>Premier</td>\n",
       "      <td>2009-2010</td>\n",
       "      <td>E0</td>\n",
       "      <td>2010-01-26</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>H</td>\n",
       "      <td>1.50</td>\n",
       "      <td>3.40</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>3.75</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.57</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.57</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72341</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Eredivisie</td>\n",
       "      <td>2006-2007</td>\n",
       "      <td>N1</td>\n",
       "      <td>2006-10-09</td>\n",
       "      <td>Nijmegen</td>\n",
       "      <td>AZ Alkmaar</td>\n",
       "      <td>A</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.72</td>\n",
       "      <td>4.20</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.73</td>\n",
       "      <td>4.20</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21408</th>\n",
       "      <td>England</td>\n",
       "      <td>League1</td>\n",
       "      <td>2010-2011</td>\n",
       "      <td>E2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>Tranmere</td>\n",
       "      <td>Rochdale</td>\n",
       "      <td>D</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.35</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13509</th>\n",
       "      <td>England</td>\n",
       "      <td>Conference</td>\n",
       "      <td>2008-2009</td>\n",
       "      <td>EC</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>Grays</td>\n",
       "      <td>Ebbsfleet</td>\n",
       "      <td>H</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39717</th>\n",
       "      <td>France</td>\n",
       "      <td>Division2</td>\n",
       "      <td>2009-2010</td>\n",
       "      <td>F2</td>\n",
       "      <td>2009-10-30</td>\n",
       "      <td>Istres</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>H</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.90</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.90</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.90</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Country   Competition     Season Div       Date     HomeTeam  \\\n",
       "13327      England    Conference  2008-2009  EC 2008-09-20  Rushden & D   \n",
       "5718       England  Championship  2007-2008  E1 2008-12-01      Cardiff   \n",
       "19366      England       League1  2006-2007  E2 2007-06-04   Scunthorpe   \n",
       "21120      England       League1  2010-2011  E2 2010-08-21    Peterboro   \n",
       "38896       France     Division2  2006-2007  F2 2006-08-09       Bastia   \n",
       "34777      England       Premier  2009-2010  E0 2010-01-26    Tottenham   \n",
       "72341  Netherlands    Eredivisie  2006-2007  N1 2006-10-09     Nijmegen   \n",
       "21408      England       League1  2010-2011  E2 2011-01-02     Tranmere   \n",
       "13509      England    Conference  2008-2009  EC 2009-01-01        Grays   \n",
       "39717       France     Division2  2009-2010  F2 2009-10-30       Istres   \n",
       "\n",
       "             AwayTeam FTR   WHH   WHD   WHA   SBH   SBD   SBA   IWH  IWD  IWA  \\\n",
       "13327          Burton   H  2.10  3.20  3.00  2.10  3.20  3.10  2.10  3.1  3.0   \n",
       "5718   Sheffield Weds   H  1.73  3.40  4.00  1.85  3.25  4.00  1.80  3.2  3.7   \n",
       "19366          Yeovil   H  1.70  3.30  4.33  1.73  3.40  4.33  1.70  3.3  4.0   \n",
       "21120    Huddersfield   H  2.50  3.20  2.80  2.35  3.25  2.70  2.30  3.1  2.6   \n",
       "38896           Dijon   D  1.90  2.75  4.25  1.95  2.88  4.00  1.85  2.7  4.4   \n",
       "34777          Fulham   H  1.50  3.40  6.00  1.50  3.75  6.00  1.57  3.6  6.0   \n",
       "72341      AZ Alkmaar   A  3.80  3.50  1.72  4.20  3.50  1.73  4.20  3.2  1.7   \n",
       "21408        Rochdale   D  2.40  3.30  2.90  2.30  3.25  2.80  2.40  3.1  2.5   \n",
       "13509       Ebbsfleet   H  2.30  3.20  2.62  2.30  3.20  2.75  2.10  3.3  2.8   \n",
       "39717           Sedan   H  2.40  2.90  3.00  2.30  2.90  3.00  2.30  2.9  3.0   \n",
       "\n",
       "        GBH   GBD   GBA  \n",
       "13327  2.00  3.20  3.20  \n",
       "5718   1.85  3.25  4.00  \n",
       "19366  1.75  3.40  4.25  \n",
       "21120  2.40  3.25  2.65  \n",
       "38896  1.91  2.85  4.00  \n",
       "34777  1.57  3.75  5.75  \n",
       "72341  4.60  3.50  1.66  \n",
       "21408  2.35  3.25  2.75  \n",
       "13509  2.30  3.25  2.75  \n",
       "39717  2.35  2.90  3.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries   :  11\n",
      "Competitions:  22\n",
      "Seasons     :  316\n",
      "Teams       :  643\n",
      "Matches     :  105503\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "parse_dates=[\"Date\"]\n",
    "ds = pd.read_csv(\"../Data/Interim/main_competitions.csv\", parse_dates=parse_dates, index_col=False)\n",
    "display(ds.dropna().sample(10))\n",
    "\n",
    "n_countries = ds['Country'].nunique()\n",
    "print (\"Countries   : \", n_countries)\n",
    "n_competitions = ds[['Country','Competition']].drop_duplicates().count()[0]\n",
    "print (\"Competitions: \", n_competitions)\n",
    "n_seasons = ds[['Country','Competition', 'Season']].drop_duplicates().count()[0]\n",
    "\n",
    "print (\"Seasons     : \", n_seasons)\n",
    "n_teams = ds['HomeTeam'].nunique()\n",
    "print (\"Teams       : \", n_teams)\n",
    "n_matches = ds.count()[0]\n",
    "print (\"Matches     : \", n_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Expected outcome\n",
    "\n",
    "The expected outcomes of this project are:\n",
    "\n",
    "- Variable or indicator that allows to assess the **success of a betting house** in his predictions. This indicator will use the values of the quotas compared with the result of the matches to determine the success of the betting house prediction.\n",
    "\n",
    "\n",
    "- Machine learning model that predicts the **result of a match**, within the framework of the country, competition and specific moment. It will indicate  the probability of success of the local or away team. \n",
    "\n",
    "\n",
    "- Method that identifies matchies with **greater divergence** between forecasts and therefore with more possibility of benefit if the result is correct.\n",
    "\n",
    "In the **production environment** data will be updated weekly, that is the update periodicity of the source data page. The update will be a batch process scheduled automatically. After updating the information  the process will be retrained and result files will be created.\n",
    "\n",
    "User will access result files and he will make his analysis using it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Success of a betting house\n",
    "\n",
    "In fact this indicator is the **'Accuracy'** because it is 'Success (TP and TN) related to total matches.\n",
    "\n",
    "We expect to define a function like this: **accuracy (match, bethouse, scope)**\n",
    "\n",
    "With params:\n",
    "\n",
    "    match: Full information (register) of a match\n",
    "    bethouse: Abrevation of the Bet House. Values: WH, SB, IW, GB\n",
    "    scope: Columns to filter information. Values: Country, Competition, Season, Team or combination of them.\n",
    "\n",
    "This function will calculate accuracy = success/matches of a concret Bet House in the selected scope and in reference to the desired match.\n",
    "\n",
    "Example: match =\n",
    "\n",
    " Country     Competition     Season     Div     Date     HomeTeam     AwayTeam     FTR     WHH     WHD     WHA     SBH     SBD     SBA     IWH     IWD     IWA     GBH     GBD     GBA\n",
    "\n",
    "0 Belgium JupilerLeague 2003-2004 B1 2003-08-08 Club Brugge Genk H NaN NaN NaN 1.44 3.75 6.5 1.45 3.8 5.4 1.4 3.8 6.85\n",
    "\n",
    "result = accuracy(match, 'WH', ['Spain'])\n",
    "\n",
    "result = 0.6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divergence\n",
    "\n",
    "In a individual match divergence it's a measure of the difference between Bet House Quotes.\n",
    "\n",
    "We expect to define a function like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1. Calculate Divergence(row)\n",
    "2. Filter matches of this week. Optional we can filter also by country or competition\n",
    "3. Map rows calculating divergence\n",
    "4. Reduce result and obtain top N divergence values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this function following these steps:\n",
    "\n",
    "1. Filter matches of this week. Optional we can filter also by country or competition\n",
    "\n",
    "2. Map rows calculating divergence\n",
    "\n",
    "3. Reduce result amb obtain top N divergence values \n",
    "\n",
    "Result will be a Dataframe with the N rows with highest divergence, that they are the ones we need to pay attention to.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Model\n",
    "\n",
    "Probably we will use a Classification Model, not selected yet, but that obtains a percentage of probability of win, draw or lose.\n",
    "\n",
    "Example:\n",
    "features = ['Country','Competition','Season','HomeTeam','AwayTeam','WHH','WHD','WHA','SBH','SBD','SBA','IWH','IWD','IWA','GBH','GBD','GBA']\n",
    "\n",
    "label = 'FTR'\n",
    "\n",
    "model = Model.train(features, label)\n",
    "\n",
    "prediction = model.predict(features)\n",
    "\n",
    "Result:\n",
    "\n",
    "Win: 'Belgium JupilerLeague 2003-2004 B1 2003-08-08 Club Brugge Genk  ...', 0.60\n",
    "\n",
    "Drop: 'Belgium JupilerLeague 2003-2004 B1 2003-08-08 Club Brugge Genk  ...', 0.30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Success Measures\n",
    "\n",
    "The result of these variables and methods will be compared with the actual results of the new test data.\n",
    "\n",
    "We have defined two sets of data:\n",
    "\n",
    "- **Main** dataset: Include all the information\n",
    "\n",
    "\n",
    "- **Recent** dataset: Include information form seassons 2017-18 and 2018-19\n",
    "\n",
    "We have divided every dataset in two subdataset:\n",
    "\n",
    "- Dataset for **training** the machine learning prediction model. It include randow 80% of information.\n",
    "\n",
    "\n",
    "- Dataset for **test** de result of the model. It include 20% of informationn\n",
    "\n",
    "<img src=\"../Img/calendari_anys.jpg\">\n",
    "\n",
    "If the goal of the test is predict if home team will gain the match, after calculate predictions with test dataset we could found the following **possible situations**:\n",
    "\n",
    "* **True Positive:** The prediction and the actual result are the same, home team has won the match.\n",
    "\n",
    "\n",
    "* **True Negative:** The prediction and the actual result are the same, home team has lost the match.\n",
    "\n",
    "\n",
    "* **False Positive:** The prediction and the actual result differ, the prediction is that the home team will win the match but the actual result is that it has lost\n",
    "\n",
    "\n",
    "* **False Negative:** The prediction and the actual result differ, the prediction is that the home team will lose the match but the actual result is that it has won\n",
    "\n",
    "<img src=\"../Img/results_schema.gif\">\n",
    "\n",
    "Our model will be any type of classification. We can test it with this **indicators**: \n",
    "\n",
    "- **Accuracy:** among all the sample, how many are correct \n",
    "$$ acc = \\frac{TP+TN}{TP+TN+FP+FN}$$\n",
    "\n",
    "\n",
    "- **Precision:** for those for which the model said as positive, how many of them are correct \n",
    "$$ prec = \\frac{TP}{TP+FP} $$\n",
    "\n",
    "\n",
    "- **Recall:** for those which are actually real, how many of them my model can label correctly \n",
    "$$ rec = \\frac{TP}{TP+FN} $$\n",
    "\n",
    "\n",
    "- **F1 measure:**\n",
    "$$ F = 2 \\cdot \\frac{prec \\cdot acc}{prec + acc} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Activity & Timing\n",
    "\n",
    "The tasks for the development of this project will be:\n",
    "\n",
    "- Selection of the origin of the data and download and comprehension of information.\n",
    "\n",
    "    \n",
    "- Cleaning of files, logic organisation and data correction validation.\n",
    "\n",
    "    \n",
    "- Selection of final fields and file and consolidation of all data files in a single dataset.\n",
    "\n",
    "    \n",
    "- Preliminary analysis of data. Statistical description of information.\n",
    "\n",
    "    \n",
    "- Analysis of different machine learning models and creation of our model.\n",
    "\n",
    "    \n",
    "- Test of the model and presentation of results.\n",
    "\n",
    "\n",
    "<img src=\"../Img/gant.gif\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Dependencies, Assumptions & Constraints\n",
    "\n",
    "### Dependencies:\n",
    "\n",
    "We don’t know yet how to generate a probabilistic model to help us in our objective.\n",
    "\n",
    "### Assumptions:\n",
    "\n",
    "We are assuming that the information we get from the page is correct.\n",
    "\n",
    "We are assuming that the page will always be updating the information with the games of each week.\n",
    "\n",
    "We are assuming that the new information uploaded to the page will keep the same structure.\n",
    "\n",
    "### Constraints:\n",
    "Webpage source of information must be active and it must continue providing information weekly.\n",
    "\n",
    "Structure of source information will not change and will be as accurate as nowadays.\n",
    "\n",
    "Hardware production infrastructure must be provided by the client and depends on other technical providers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Technical Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Solution Description & Diagram\n",
    "A costumes has ordered us to develop a system to predict the result of football matches based on the quotas from the betting houses.\n",
    "\n",
    "We have identified the website: http://www.football-data.co.uk/data.php with all the information we can need to develope the solution and that it's updated weekly.\n",
    "\n",
    "The front-end will consist in a the page with to main options:\n",
    "\n",
    "* Update information: Will download latest information from source web page and show to user result as number of matches by country and competition.\n",
    "\n",
    "* Get weekly prediction: User will select initial and final date of the analysis, by default current week. Solution will show a screen with 4 frames:\n",
    "   * Betting houses realibility: Graphic with the reliability of bethouses included in dataset in all the seasons.\n",
    "   * Top N greatest divergent matches: Description of the N matches with highest divergence in this week and his prediction\n",
    "   * Top N lowes divergent matches: Description of the N matches with lowest divergence in this week and his prediction\n",
    "   * Rest of the matches: List of the rest of the matches in the week.\n",
    "   \n",
    "* Get individual prediction: The user will select initial and final date and the match (country, competition and team). User will show all the information of the match, including prediction.\n",
    "\n",
    "The back-end of the solution will be developed with Spark tools: RDD, Pandas and DataFrames\n",
    "\n",
    "Data information will be in csv files.\n",
    "\n",
    "The process of calculation is:\n",
    "\n",
    "<img src=\"../Img/esquema.gif\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Inputs\n",
    "The original data has been obtained from the website: http://www.football-data.co.uk/data.php\n",
    "\n",
    "This webpage offers a large dataset of information about football matches for up to 25 European league divisions and other international leagues. This information comes from 15 seasons back to 2003-20004 and include more than 500 football teams.\n",
    "\n",
    "Original files also includes information related quotas calculated by different bets houses based on probability of win, draw or lost.\n",
    "\n",
    "Information is provided in csv files classified in folders by season, country and competition.\n",
    "\n",
    "This website provides to separate datasets: main competitions and extra competitions. We have only dealt with the main leagues.\n",
    "\n",
    "Our first process is responsible for downloading all this files and reorder in folders by country, competition and season, that it fits better to the subsequent treatment we will do.\n",
    "\n",
    "This process is developed in notebook  '**1_download-raw.ipynb**'.\n",
    "\n",
    "The following table shows the distribution of the downloaded data, grouped by country and competition. We can show de minimum and maximum session in every competition and the number of sessions. In fact every season it’s a separate file.\n",
    "\n",
    "<img src=\"../Img/original_data.gif\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning Steps\n",
    "\n",
    "The task that has supposed more work is the validation and treatment of the **downloaded files**. Initially we have download all the files in both datasets (main and extra).\n",
    "\n",
    "The first part of cleaning process was validate downloaded files. We have detected almost 40 files with erroneous format, because the weren’t correct csv files.. We have discarded this information.\n",
    "\n",
    "The next step was to identify the **common fields**. Since each combination of country, competition and season was a separate file, it could contain different fields. This has happened especially with the data of the betting houses. The cause of this situation is that each betting house operates in different countries and has had activity in different periods of time.\n",
    "\n",
    "This process was developed in '**2_filesAnalysis-raw_to_correct.ipynb**'\n",
    "\n",
    "We have reviewed the distribution of bookmakers by country and incorporated into our dataset houses with information in most countries. Finally we have included in our dataset 12 betting houses.\n",
    "The following table is an example of the analysis of the distribution of betting houses.\n",
    "\n",
    "<img src=\"../Img/bet_houses_distrib.gif\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After verification of files next step was **unifying** all files in a global dataset called 'main_competitions.csv'. \n",
    "\n",
    "As a part of this task we have selected want fields to include:\n",
    "\n",
    "* Classification files: Country, Competition and Season\n",
    "* Match information: Date, HomeTeam, AwayTeam, FTR (Full time result)\n",
    "* Betting houses quotas. Fields names ara composed by the betting house id and the type of quota id.\n",
    "    * Betting houses ids are: B365,BS,BW,GB,IW,LB,SO,SB,SJ,SY,VC,WH\n",
    "    * Quota types ids are: H (Home), D (Draw), A (Away)\n",
    "\n",
    "This proces was developed in notebook '**3_filesUnifying-raw_to_correct.ipynb**'\n",
    "\n",
    "We have also created a second dataset with matches from **seasons 2017-2018 and 2018-2019**, that will be used in the prediction model and it's called 'main_competitions_recent.csv'\n",
    "\n",
    "We have reavaluate the betting houses fields to identify if all of them were used. We detect and drop columns from 4 houses with nulls in all the records of this seasons. Finally this dataset contains 6 betting houses quotas.\n",
    "\n",
    "This process was developed in notebook '**5_recent_seasons_subset.ipynb**' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step was validate that **fields** of our dataset are **correct**. In this case all the fields have the correct type and format.\n",
    "\n",
    "This step was developed in '**4_fieldsAnalysis-raw_to_correct.ipynb**'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step of cleaning was validate **consistency of fields**. \n",
    "\n",
    "This proces was developed in '**5_fieldsAnalysis-correct_to_consistent.ipynb**'\n",
    "\n",
    "We made the following validations:\n",
    "\n",
    "* Null values required: We validated nulls in required fields and deleted corresponding rows:\n",
    "    * Date: 145 rows\n",
    "    * HomeTeam and AwayTeam: 385 rows\n",
    "    * FTR: 146 rows\n",
    "    \n",
    "    \n",
    "* Null values bet houses: We reviewed nulls in betting houses quotas. We decide to drop columns of betting house with almost rows with nulls, in this case: SO and SY. We maintain the rest of the Betting Houses cols unles nulls because we will delete before every specific analisys.\n",
    "\n",
    "In the analysis phase we create subdatasets and we review nulls in every specific subdataset.\n",
    "\n",
    "To remove nulls in this case there are to possible strategies: remove cols (Bets houses) or rows (matches). We decide a mixed strategy. We detect automatically Bets houses quotes with a large number of nulls (<80% correct values) and drop his columns. In consequence rest of columns has a high level of information. Then we drop rows with nulls.\n",
    "\n",
    "In the case of 'recent' dataset we have dropped 'LB' bets house (67% not null) and maintain 5 bets houses. After dropping nulls rows we keep '99.38%' of rows.\n",
    "\n",
    "This specific part is developed in notebook '**8_NaiveBayesModel-probabilities.ipynb**'\n",
    "\n",
    "* Unify team names: We have detected teams with different names and unifidied the names\n",
    "\n",
    "\n",
    "<img src=\"../Img/team_names.gif\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Processing Steps\n",
    "\n",
    "### 4.1 Divergence\n",
    "\n",
    "To assess the different valuation that betting houses have given to a match we have created the measured 'divergence'.\n",
    "\n",
    "We calculate the divergence as the maximum percentage of variation between quotas and them mean of quotas of the match. All this is made by every type of quota (H, D, A).\n",
    "\n",
    "In first place we identify the betting houses and columns included in the dataset with function 'filterBetHouses'.\n",
    "\n",
    "Then we calculate the divergence of every individual match with function '**calcDivergence**'.\n",
    "\n",
    "Bellow this we map this calculation for all the rows in the dataset.\n",
    "\n",
    "And finally we have implemented the function '**topNDivergence**' to obtain the top N matches with highest divergence and the top N matches with de lowest divergence.\n",
    "\n",
    "To analyse divergence values we have calculated histogram of its values. This measure has a binomial distribution with values from almost 0% to 80%, with a central value of 7-8%. Central quartiles are between 5,42% and 9,69%. \n",
    "\n",
    "Distance between divergences it's small, with only 4,27% of interquartile distance, and 80% of values have only a maximum distance of 10%.\n",
    "\n",
    "Next graph shows histogram amb values of mean, median, and percentiles 10%, 25%, 75% and 100%.\n",
    "\n",
    "\n",
    "<img src=\"../Img/divergence1.gif\">\n",
    "\n",
    "When we will analyse lower and higher divergent matches we will take as limits values from quantiles 10% (4,31%) and 90% (14,06%).\n",
    " \n",
    "This has been developed in notebook '**7_divergence.ipynb**'\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellow this we have add this measure to datased and saved it to disc.\n",
    "\n",
    "This action has been done with function '**calcAndSaveDivergence**'.\n",
    "\n",
    "This function uses auxiliar functions like 'reformatRow', 'reformatRDD', 'createDataFrame' and 'saveDFtoCSV' to transform result from 'calcDivergence' function to the needed structured to save dataset again on the disc.\n",
    "\n",
    "We have added Divergence field in both datasets: main_competitions and main_competitions_recent.\n",
    "\n",
    "This has been developed in notebook '**7_divergenceSave.ipynb**'\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Bet Houses Reliability\n",
    "\n",
    "\n",
    "To calculate the reliability of each bethouse, we take a look at all the historical of quotas. Then, for each match we take into account only two columns: __FTR__ (Final Time Result) and __the lowest quota of the bethouse for that match__. The lowest of the quotas is what the bethouse has considered the most probable result for that match. Then, the computation is trivial: if __FTR__ is equal to the lowest quota, means that the bethouse has hit the result, otherwhise, not. Then, we just devide the hits between the total number of bets of that bethouse to obtain his reliability.\n",
    "\n",
    "The reliability of our bethouses looks like this:\n",
    "\n",
    "<img src=\"../Img/reliability.png\">\n",
    "\n",
    "As the image shows, there is a high correlation between all the quotas of the bethouses as more or less they have the same hit ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Prediction of the mach result\n",
    "\n",
    "In order to predict the match result we have decided to use a classificator model based in __Naive Bayes__. We have been discussing to use some other kinds of models like __Linear Regression__, __Linear Regression with Stochastic Gradient Descent(SGD)__ or __Multinomial Logistic Regression__ but, we have discarded them because we are aiming for another type of outcome. What we want is to get for a match the probability of the three different possible results. \n",
    "\n",
    "For example, a desired outcome would be this one: (__Home Wins__: 45%, __Draw__ : 25%, __Away Wins__ : 30%)\n",
    "\n",
    "This kind of outcome can only be obtained by using a __Naive Bayes__ model.\n",
    "\n",
    "Finally, we have decided to create two different __Naive Bayes__ models. The first one, will be trained with all the bets historical and the second one, will be trained only with the bets from the current season (2018-2019).\n",
    "We have taken this decision because we wanted to see if the model performance increases if we take some more concrete data. Also, may be interesting to create a model with only the quotas for one competition, country or team.\n",
    "\n",
    "To create this two models, we have just used the __FTR__ column as the __label__ and all the quotas from the bethouses as the __features__ vector.\n",
    "\n",
    "Finally, we have split the datasets in 90% for training and 10% for testing.\n",
    "\n",
    "The performance of our first model is the following:\n",
    "\n",
    "<img src=\"../Img/full_ds.png\">\n",
    "<img src=\"../Img/full_th.png\">\n",
    "<img src=\"../Img/full_hh.png\">\n",
    "<img src=\"../Img/full_dh.png\">\n",
    "<img src=\"../Img/full_ah.png\">\n",
    "\n",
    "\n",
    "The performance of our second model is the following:\n",
    "\n",
    "<img src=\"../Img/partial_ds.png\">\n",
    "<img src=\"../Img/partial_th.png\">\n",
    "<img src=\"../Img/partial_hh.png\">\n",
    "<img src=\"../Img/partial_dh.png\">\n",
    "<img src=\"../Img/partial_ah.png\">\n",
    "\n",
    "\n",
    "\n",
    "As it can be seen, in both cases the models seem to be struggling in the draw predictions. This is why their accuracy is only of more or less 50%.\n",
    "\n",
    "As we can see, if the data is more concrete, the performance increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation with RDD\n",
    "\n",
    "To obtain a more precise prediction we don't have enough to calculate the most probable result. We need to know the probability of every result.\n",
    "\n",
    "We try calculate it with NaiveBayesModel of library mllib, that works with RDDs. This model provide PI logs (probability of result values) and **THETA** logs (array of probabilities of parameters conditioned to ).\n",
    "\n",
    "We calculation from logs of **PI** and **THETA** to probabilities of result must be done manually.\n",
    "\n",
    "Given a list of bets(matrix of 1 row and as much columns as number of bets), to generate the probability of each result, we have to multiply **THETA** by the list of bets and then add **PI**. The result of this operations will be an unidimensional matrix of three numbers ([a, b, c]). To get the real probabilities what we need to do is to perform the folowwing operation:\n",
    "\n",
    "[e^a / e^a + e^b + e^c, e^b / e^a + e^b + e^c, e^c / e^a + e^b + e^c] (Being e the **Euler number**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation with Dataframes\n",
    "\n",
    "At this point we have tried too the **ML package**, that works with Spark DataFrames. This package includes also a NaiveBayesModel implemented. The objective was if we can obtain same results with both packages.\n",
    "\n",
    "We have developped a second version of functions to create, train and test the model.\n",
    "\n",
    "Function '**calcModelAndPrediction**' mades all this work and it's developped in notebook '**8_NaiveBayesModel-DataFrame.ipynb**'\n",
    "\n",
    "This are the followed steps:\n",
    "* **cleanNulls**: Removes null information. \n",
    "\n",
    "We decide don't replace nulls with a default value or calculation because this will modify predictions.\n",
    "\n",
    "To remove nulls there are to possible strategies: remove cols (Bets houses) or rows (matches). We decide a mixed strategy. We detect automatically Bets houses quotes with a large number of nulls (<80% correct values) and drop his columns. In consequence rest of columns has a high level of information. Then we drop rows with nulls. \n",
    "\n",
    "In the case of 'recent' dataset we have dropped 'LB' bets house (67% not null) and maintain 5 bets houses. After dropping nulls rows we keep '99.38%' of rows.\n",
    "\n",
    "* **calcBetsHousesCols**: Obtain the list of bets houses quotas columns\n",
    "This function checks dataset columns and it determine available columns to use as parameters of the model.\n",
    "\n",
    "\n",
    "* **Split taining and test**\n",
    "We split resulting dataset in two aleatory subsets. 80% it's used to train dataset and 20%  it's used to test dataset.\n",
    "\n",
    "\n",
    "* **calcNaiveBayesModel**: Calculate Naive Bayes Model\n",
    "We transform result to numeric values (H=0, D=1, A=2), after we create vector of labels and parameters create the model with the 'multinomial' type and fit (train) the model.\n",
    "After this we calculate the prediction, with the 'transform' method. In this point it's when we obtain probabilities.\n",
    "\n",
    "\n",
    "* **Evaluate model**\n",
    "To avaluate the model we have used the '**MulticlassClassificationEvaluator**' class and the 'Accuracy' metric.\n",
    "We use only accuracy metric because it's values are relatively low and has not sense calculate other metrics.\n",
    "\n",
    "**Accuracy** values are:\n",
    "\n",
    "Model: 48.16 %\n",
    "\n",
    "Prediction: 47.44 %\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we have implemented a function to obtain the prediction of matche in a country and period of time, by default a week. \n",
    "For example we have predicted result of matches in Spain in the first week of november. \n",
    "\n",
    "The function is called '**calcWeekPrediction**' and it take the original dataframe, the model calculated with 'calcNaiveBayesModel' function, the country name, the initial date and the final date.\n",
    "This function follow almost the same steps as previous function 'calcModelAndPrediction':\n",
    "\n",
    "- Filter dataset by country and dates.\n",
    "\n",
    "- Converts result labels to numeric values.\n",
    "\n",
    "- Clean nulls in columns and rows\n",
    "\n",
    "- Creates vector with label and features for prediction\n",
    "\n",
    "- Calculated the prediction with:  predict = model.transform(vecWeek)\n",
    "\n",
    "- Reorder and reformat columns of resulting dataset to show result\n",
    "\n",
    "This it's a sample of resulting prediction:\n",
    "\n",
    "<img src=\"../Img/week_prediction.gif\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition by divergence\n",
    "\n",
    "We want to know whether divergence measure affects prediction of results and the accuracy of the model.\n",
    "\n",
    "To do this analysis we have used dataset 'main_competition_recent' and versioned functions defined in previous notebook. We have divided information in three subdatsets depending on the value of divergence:\n",
    "\n",
    "- Lower divergence: Matches in the 10% lower interval, that is, values below 4.31.\n",
    "\n",
    "- Higher divergence: Matches in the 10% upper interval, that is, values over 14.61\n",
    "\n",
    "- Central divergence: Matche in the 80% central interval. Values between 4.31 and 14.61\n",
    "\n",
    "In addition every subdataset have been divided also two parts. Model: 80%, test: 20%\n",
    "\n",
    "We have calculated accuracy of the model and the test in all the subsets. Following graph represent accuracy calculated:\n",
    "\n",
    "<img src=\"../Img/divergence_accuracy.gif\">\n",
    "\n",
    "Higher divergence subdataset has a good accuracy value around 70%, but the restant datasets have a similar accuracy as the normal model. \n",
    "\n",
    "We made also a more detailed partitioning of dataset by deciles of divergence and result confirm that accuracy increase with divergence value. This is probably because these matches have a very clear result prediction from bets houses point of view.\n",
    "\n",
    "<img src=\"../Img/divergence_accuracy2.gif\">\n",
    "\n",
    "Finally we try to add the 'Divergence' measure as a parameter of the model, and result was similar to the original model:\n",
    "\n",
    "* Naive Bayes Model with Divergence\n",
    "\n",
    "Model accuracy     :  47.81 %\n",
    "\n",
    "Prediction accuracy:  48.13 %\n",
    "\n",
    "* Naive Bayes Model without Divergence\n",
    "\n",
    "Model accuracy     : 48.16%\n",
    "\n",
    "Prediction accuracy: 47.44%\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition by Country\n",
    "\n",
    "We're interested in know if other variables can affect model prediction. We take the case of the 'Country' variable. \n",
    "\n",
    "Following the same steps as with the measure 'Divergence' we partitioned the dataset by country and we calculated the model and test accuracy.\n",
    "\n",
    "<img src=\"../Img/country_accuracy.gif\">\n",
    "\n",
    "Only a few countries (greece, portugal, italy, ...) have a higher accuracy taking a partial dataset partitioned by country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Outcomes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Review Expected vs. Attained Outcomes\n",
    "\n",
    "All our expected outcomes has been achieved.\n",
    "\n",
    "We have developed functions to calculated divergence of matches and identify top N divergent matches.\n",
    "\n",
    "We also have developed a proces to obtain the reliability of betting houses and we have calculated with main competitions dataset.\n",
    "\n",
    "We have obtain a prediction of the result based in **Naive Bayes** that provides a result like this: (__Home Wins__: 45%, __Draw__ : 25%, __Away Wins__ : 30%).\n",
    "\n",
    "We have codified the result so:\n",
    "    0 : Home wins\n",
    "    1 : Draw\n",
    "    2 : Away wins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Review Final Outcomes vs. Objectives\n",
    "\n",
    "\n",
    "The accuracy of our models right now is of more or less 50%.\n",
    "\n",
    "We expected to obtain the same prediction accuracy for all the three different results. But, as we have explained, the models seem to have problems to predict the draws so that is decreasing the final global accuracy.\n",
    "\n",
    "Note that if we achieve for the models to predict draws as good as they predict local and away victories, the final global accuray will be of almost 70%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusions and Future Steps\n",
    "\n",
    "As we have seen, the model seems to work better when the date used us more concrete. So it would be a good idea to try to create new models with the bets for only one team, competition or country.\n",
    "\n",
    "Finally, we can also try some other interesting kind of models like the associative ones. Maybe it would be a good idea to give a try to __A-Priori__ to try to find some associative rules (if they exist) between bets and results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
